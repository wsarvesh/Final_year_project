{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "from tweepy.streaming import StreamListener\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy import Stream\n",
    "import pandas as pd\n",
    "import json\n",
    "import dataset\n",
    "import credentials\n",
    "import sqlite3\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "import pickle\n",
    "from Naive_bayes_model import *\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('nb1.pickle', 'rb')\n",
    "NBayesClassifier = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = open('rfp', 'rb')\n",
    "RFClassifier = pickle.load(f1)\n",
    "f1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('tweet2.db')\n",
    "c = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred(data):\n",
    "    \n",
    "    tweetProcessor = PreProcessTweets()\n",
    "    preprocessedTrainingSet = tweetProcessor.processTweets(data)\n",
    "    \n",
    "    word_features = buildVocabulary(preprocessedTrainingSet)\n",
    "#     print(\"\\n\",word_features,\"\\n\")\n",
    "#     buildVocabulary(preprocessedTrainingSet)\n",
    "    trainingFeatures = nltk.classify.apply_features(extract_features, preprocessedTrainingSet)\n",
    "    \n",
    "    print(preprocessedTrainingSet[0][0])\n",
    "    \n",
    "    NB = NBayesClassifier.classify(extract_features(preprocessedTrainingSet[0][0],word_features))\n",
    "    \n",
    "    return NB\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def attributeselection(text,query_word):\n",
    "    attr= []\n",
    "\n",
    "    #text = \"Alleged East Bay serial arsonist arrested #SanFrancisco - http://t.co/ojuHfkHVb2\"\n",
    "    text = nltk.word_tokenize(text)\n",
    "    poslist = nltk.pos_tag(text)\n",
    "#     print(poslist)\n",
    "\n",
    "    verblist = []\n",
    "    for i in range(len(poslist)):\n",
    "        if poslist[i][1].startswith('V'):\n",
    "            verblist.append(poslist[i])\n",
    "    \n",
    "    word_count = len(poslist)\n",
    "#     print(word_count)\n",
    "\n",
    "    if len(verblist) == 0:\n",
    "        l = (query_word,'VB')\n",
    "        verblist.append(l)\n",
    "    \n",
    "#     print(verblist,\"\\n\")\n",
    "    verb_count = len(verblist)\n",
    "#     print(verb_count)\n",
    "\n",
    "   # query_word = 'arson'\n",
    "\n",
    "    words_before = words_after = 0\n",
    "    for i in range(len(poslist)):\n",
    "        if poslist[i][0].startswith(query_word):\n",
    "            words_before = i\n",
    "\n",
    "    words_after = word_count - words_before - 1\n",
    "\n",
    "#     print(words_before)\n",
    "#     print(words_after)\n",
    "    verbs = []    \n",
    "    attr.append(word_count)\n",
    "#     for i in verblist:\n",
    "#         print(i[0])\n",
    "#         verbs.append(i[0])\n",
    "#     attr.append(verbs)\n",
    "    attr.append(verb_count)\n",
    "    attr.append(words_before + 1)\n",
    "#     attr_query_word.append(query_word)\n",
    "    attr.append(words_before)\n",
    "    attr.append(words_after)\n",
    "    \n",
    "    \n",
    "        \n",
    "    column_names = ['no_of_words', 'no_of_verbs', 'pos_query_word', 'word_before', 'word_after']\n",
    "    print(attr,column_names)\n",
    "    df = pd.DataFrame([attr], columns=column_names)\n",
    "    arr_x=df.to_numpy(dtype=object)\n",
    "    print(arr_x,arr_x.shape)\n",
    "    y_pred = RFClassifier.predict(arr_x)\n",
    "    print(\"PRIORITY: \",y_pred)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwitterStreamer():\n",
    "    \n",
    "    def stream_tweets(self, fetched_tweets_filename, hash_tag_list):\n",
    "        listener = StdOutListener(fetched_tweets_filename)\n",
    "        auth = OAuthHandler(credentials.CONSUMER_KEY, credentials.CONSUMER_SECRET)\n",
    "        auth.set_access_token(credentials.ACCESS_TOKEN, credentials.ACCESS_TOKEN_SECRET)\n",
    "        \n",
    "        stream = Stream(auth, listener,tweet_mode='extended')\n",
    "        \n",
    "        stream.filter(languages=[\"en\"],track=['coronavirus'])\n",
    "        \n",
    " \n",
    "class StdOutListener(StreamListener):\n",
    "    \n",
    "    def on_status(self, status):\n",
    "        print(status.text)\n",
    "\n",
    "    def on_error(self, status):\n",
    "        print(status)\n",
    "\n",
    "    def on_data(self, data):\n",
    "        all_data             = json.loads(data)\n",
    "        created_at           = all_data['created_at']\n",
    "        favorite_count       = all_data['favorite_count']\n",
    "        favorited            = all_data['favorited']\n",
    "        filter_level         = all_data['filter_level']\n",
    "        lang                 = all_data['lang']\n",
    "        retweet_count        = all_data['retweet_count']\n",
    "        retweeted            = all_data['retweeted']\n",
    "        source               = all_data['source']\n",
    "        text                 = all_data['text']\n",
    "        truncated            = all_data['truncated']\n",
    "        user_created_at      = all_data['user']['created_at']\n",
    "        user_followers_count = all_data['user']['followers_count']\n",
    "        user_location        = all_data['user']['location']\n",
    "        user_lang            = all_data['user']['lang']\n",
    "        user_name            = all_data['user']['name']\n",
    "        user_screen_name     = all_data['user']['screen_name']\n",
    "        user_time_zone       = all_data['user']['time_zone']\n",
    "        user_utc_offset      = all_data['user']['utc_offset']\n",
    "        user_friends_count   = all_data['user']['friends_count']\n",
    "        geo_enabled          = all_data['user']['geo_enabled']  \n",
    "        coordinates          = all_data['coordinates']\n",
    "        geo                  = all_data['geo']\n",
    "        place                = all_data['place']\n",
    "        if place is not None:\n",
    "            place_name       = all_data['place']['name']\n",
    "        else:\n",
    "            place_name       = all_data['place']\n",
    "        \n",
    "        print(\"Tweet: \"+text+\"\\n\")\n",
    "        \n",
    "        data = [{'text': text,'Classfication': ''}]\n",
    "        \n",
    "        info = pred(data)\n",
    "        \n",
    "        if info == 'Relevant' or info == 1 or info == '1':\n",
    "            attributeselection(text,'coronavirus')\n",
    "            \n",
    "        print(\"\\n Class: \"+info+\"\\n\")\n",
    "                         \n",
    "        c.execute('''INSERT INTO tweets \n",
    "        (created_at, favorite_count, favorited, filter_level, lang, \n",
    "                         retweet_count, retweeted, source, text, truncated, user_created_at,  \n",
    "                         user_followers_count, user_location, user_lang, user_name, \n",
    "                         user_screen_name, user_time_zone, user_friends_count,geo_enabled,coordinates,geo,place_name ) \n",
    "            VALUES (?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?)''', \n",
    "            (created_at, favorite_count, favorited, filter_level, lang, retweet_count, \n",
    "                         retweeted, source, text, truncated, user_created_at, \n",
    "                         user_followers_count, user_location, user_lang, user_name, \n",
    "                         user_screen_name, user_time_zone, user_friends_count,geo_enabled,coordinates,geo,place_name ))\n",
    "        \n",
    "        c.execute('''INSERT INTO tweet_class \n",
    "        (text, class) \n",
    "            VALUES (?,?)''', \n",
    "            (text, info))\n",
    "        \n",
    "        conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet: RT @Sam1Fleming: Germany’s coronavirus anomaly: high infection rates but few deaths https://t.co/CL0tLEsQOS via @financialtimes\n",
      "\n",
      "['rt', 'germany', '’', 'coronavirus', 'anomaly', 'high', 'infection', 'rates', 'deaths', 'via']\n",
      "[22, 1, 8, 7, 14] ['no_of_words', 'no_of_verbs', 'pos_query_word', 'word_before', 'word_after']\n",
      "[[22 1 8 7 14]] (1, 5)\n",
      "PRIORITY:  [0]\n",
      "\n",
      " Class: 1\n",
      "\n",
      "Tweet: RT @real_defender: AOC and Julian Castro are calling for investigations and resignations of  Republican Senators Burr and Loeffer for unloa…\n",
      "\n",
      "['rt', 'aoc', 'julian', 'castro', 'calling', 'investigations', 'resignations', 'republican', 'senators', 'burr', 'loeffer', 'unloa…']\n",
      "[22, 2, 1, 0, 21] ['no_of_words', 'no_of_verbs', 'pos_query_word', 'word_before', 'word_after']\n",
      "[[22 2 1 0 21]] (1, 5)\n",
      "PRIORITY:  [0]\n",
      "\n",
      " Class: 1\n",
      "\n",
      "Tweet: RT @thompsonstrain1: Come on people...\n",
      "\n",
      "['rt', 'come', 'people', '...']\n",
      "[8, 1, 1, 0, 7] ['no_of_words', 'no_of_verbs', 'pos_query_word', 'word_before', 'word_after']\n",
      "[[8 1 1 0 7]] (1, 5)\n",
      "PRIORITY:  [0]\n",
      "\n",
      " Class: 1\n",
      "\n",
      "Tweet: Coronavirus made it impossible to have useless small talk with that old friend of yours. \"we totally gotta hang out… https://t.co/lGKFyxUPat\n",
      "\n",
      "['coronavirus', 'made', 'impossible', 'useless', 'small', 'talk', 'old', 'friend', '``', 'totally', 'got', 'ta', 'hang', 'out…']\n",
      "\n",
      " Class: 0\n",
      "\n",
      "Tweet: RT @SenateGOP: \"We're asking everybody to show a little bit of kindness.\"\n",
      "\n",
      "On the ground in Iowa, @SenJoniErnst is working to fight coronav…\n",
      "\n",
      "['rt', '``', \"'re\", 'asking', 'everybody', 'show', 'little', 'bit', 'kindness', \"''\", 'ground', 'iowa', 'working', 'fight', 'coronav…']\n",
      "\n",
      " Class: 0\n",
      "\n",
      "Tweet: RT @TeaPainUSA: Dirty, dirty, dirty. https://t.co/h0opAw4itC\n",
      "\n",
      "['rt', 'dirty', 'dirty', 'dirty']\n",
      "\n",
      " Class: 0\n",
      "\n",
      "Tweet: RT @PhilipinDC: This Is How We Beat the Coronavirus - The Atlantic https://t.co/J8jwx7TQ0X\n",
      "\n",
      "['rt', 'beat', 'coronavirus', 'atlantic']\n",
      "\n",
      " Class: 0\n",
      "\n",
      "Tweet: RT @PalliThordarson: This is perhaps the most important article ever written about #COVID19 It is long but please read it. Especially #Ausp…\n",
      "\n",
      "['rt', 'perhaps', 'important', 'article', 'ever', 'written', 'covid19', 'long', 'please', 'read', 'especially', 'ausp…']\n",
      "\n",
      " Class: 0\n",
      "\n",
      "Tweet: RT @esaagar: We need a Coronavirus Truman Committee to ruthlessly investigate/prosecute charlatans, profiteers, and perhaps even members of…\n",
      "\n",
      "['rt', 'need', 'coronavirus', 'truman', 'committee', 'ruthlessly', 'investigate/prosecute', 'charlatans', 'profiteers', 'perhaps', 'even', 'members', 'of…']\n",
      "\n",
      " Class: 0\n",
      "\n",
      "Tweet: RT @NewIndianXpress: The total number of positive #Coronavirus cases rise to 223as Delhi, Mumbai prepares for a near lockdown. \n",
      "#Coronaviru…\n",
      "\n",
      "['rt', 'total', 'number', 'positive', 'coronavirus', 'cases', 'rise', '223as', 'delhi', 'mumbai', 'prepares', 'near', 'lockdown', 'coronaviru…']\n",
      "[26, 2, 1, 0, 25] ['no_of_words', 'no_of_verbs', 'pos_query_word', 'word_before', 'word_after']\n",
      "[[26 2 1 0 25]] (1, 5)\n",
      "PRIORITY:  [0]\n",
      "\n",
      " Class: 1\n",
      "\n",
      "Tweet: RT @HillaryClinton: Every voter must have the opportunity to vote by mail this year. \n",
      "\n",
      "Senators @RonWyden and @amyklobuchar have a bill to…\n",
      "\n",
      "['rt', 'every', 'voter', 'must', 'opportunity', 'vote', 'mail', 'year', 'senators', 'bill', 'to…']\n",
      "[27, 4, 1, 0, 26] ['no_of_words', 'no_of_verbs', 'pos_query_word', 'word_before', 'word_after']\n",
      "[[27 4 1 0 26]] (1, 5)\n",
      "PRIORITY:  [0]\n",
      "\n",
      " Class: 1\n",
      "\n",
      "Tweet: RT @peachyslen: to anyone who like to say “we’re not scared of coronavirus and anything, we’re only scared of god” pls give them this video…\n",
      "\n",
      "['rt', 'anyone', 'like', 'say', '“', '’', 'scared', 'coronavirus', 'anything', '’', 'scared', 'god', '”', 'pls', 'give', 'video…']\n",
      "\n",
      " Class: 0\n",
      "\n",
      "Tweet: RT @TwinklingTania: According to stock sales disclosures by Senators after a closed door briefing on January 24 about the Coronavirus threa…\n",
      "\n",
      "['rt', 'according', 'stock', 'sales', 'disclosures', 'senators', 'closed', 'door', 'briefing', 'january', '24', 'coronavirus', 'threa…']\n",
      "[23, 1, 1, 0, 22] ['no_of_words', 'no_of_verbs', 'pos_query_word', 'word_before', 'word_after']\n",
      "[[23 1 1 0 22]] (1, 5)\n",
      "PRIORITY:  [1]\n",
      "\n",
      " Class: 1\n",
      "\n",
      "Tweet: @realDonaldTrump This USA TODAY is from January. It wouldn’t be a far stretch to think Trump wasn’t briefed about t… https://t.co/DVJYrnKV78\n",
      "\n",
      "['usa', 'today', 'january', '’', 'far', 'stretch', 'think', 'trump', '’', 'briefed', 't…']\n",
      "\n",
      " Class: 0\n",
      "\n",
      "Tweet: RT @KatieMorley_: Pass on to elderly friends and relatives: If someone knocks on the door offering a) help in return for cash upfront or ca…\n",
      "\n",
      "['rt', 'pass', 'elderly', 'friends', 'relatives', 'someone', 'knocks', 'door', 'offering', 'help', 'return', 'cash', 'upfront', 'ca…']\n",
      "[29, 1, 1, 0, 28] ['no_of_words', 'no_of_verbs', 'pos_query_word', 'word_before', 'word_after']\n",
      "[[29 1 1 0 28]] (1, 5)\n",
      "PRIORITY:  [1]\n",
      "\n",
      " Class: 1\n",
      "\n",
      "Tweet: RT @ZZBolinski: tRump tells Governors to \"get their own stuff\" then the Feds corner the market on the \"stuff.\"\n",
      "Oh, business as usual.\n",
      "Massa…\n",
      "\n",
      "['rt', 'trump', 'tells', 'governors', '``', 'get', 'stuff', \"''\", 'feds', 'corner', 'market', '``', 'stuff', \"''\", 'oh', 'business', 'usual', 'massa…']\n",
      "\n",
      " Class: 0\n",
      "\n",
      "Tweet: RT @Iowlifee: Coronavirus doesnt effect rats n snakes so most of you are safe\n",
      "\n",
      "['rt', 'coronavirus', 'doesnt', 'effect', 'rats', 'n', 'snakes', 'safe']\n",
      "[16, 3, 1, 0, 15] ['no_of_words', 'no_of_verbs', 'pos_query_word', 'word_before', 'word_after']\n",
      "[[16 3 1 0 15]] (1, 5)\n",
      "PRIORITY:  [0]\n",
      "\n",
      " Class: 1\n",
      "\n",
      "Tweet: RT @brhodes: If you want to understand how catastrophically Trump has failed in this response, consider that the first cases were in the US…\n",
      "\n",
      "['rt', 'want', 'understand', 'catastrophically', 'trump', 'failed', 'response', 'consider', 'first', 'cases', 'us…']\n",
      "[27, 6, 1, 0, 26] ['no_of_words', 'no_of_verbs', 'pos_query_word', 'word_before', 'word_after']\n",
      "[[27 6 1 0 26]] (1, 5)\n",
      "PRIORITY:  [0]\n",
      "\n",
      " Class: 1\n",
      "\n",
      "Tweet: RT @DavidAFrench: The potential insider trading is dreadful and possibly criminal, but what could elevate this to a historic scandal is the…\n",
      "\n",
      "['rt', 'potential', 'insider', 'trading', 'dreadful', 'possibly', 'criminal', 'could', 'elevate', 'historic', 'scandal', 'the…']\n",
      "\n",
      " Class: 0\n",
      "\n",
      "Tweet: RT @SEACoronavirus: top 5 SE Asia #COVID19 cases :\n",
      "🇲🇾- 1030 cases, 2 deaths\n",
      "🇸🇬- 385 cases , 0 deaths\n",
      "🇮🇩- 369 cases, 32 deaths\n",
      "🇹🇭 - 322 case…\n",
      "\n",
      "['rt', 'top', '5', 'se', 'asia', 'covid19', 'cases', '🇲🇾-', '1030', 'cases', '2', 'deaths', '🇸🇬-', '385', 'cases', '0', 'deaths', '🇮🇩-', '369', 'cases', '32', 'deaths', '🇹🇭', '322', 'case…']\n",
      "[34, 1, 1, 0, 33] ['no_of_words', 'no_of_verbs', 'pos_query_word', 'word_before', 'word_after']\n",
      "[[34 1 1 0 33]] (1, 5)\n",
      "PRIORITY:  [0]\n",
      "\n",
      " Class: 1\n",
      "\n",
      "Tweet: RT @mmaher70: Tory Matt Hancock admits he couldn't live on £94-a-week sick pay \n",
      "People need help pay rent, utilities etc\n",
      "France covered it…\n",
      "\n",
      "['rt', 'tory', 'matt', 'hancock', 'admits', 'could', \"n't\", 'live', '£94-a-week', 'sick', 'pay', 'people', 'need', 'help', 'pay', 'rent', 'utilities', 'etc', 'france', 'covered', 'it…']\n",
      "\n",
      " Class: 0\n",
      "\n",
      "Tweet: Did you know that by eating tide pods you can cure the Coronavirus?\n",
      "\n",
      "['know', 'eating', 'tide', 'pods', 'cure', 'coronavirus']\n",
      "\n",
      " Class: 0\n",
      "\n",
      "Tweet: Oh me gotta do it early than usual this year....hmmmm\n",
      "\n",
      "['oh', 'got', 'ta', 'early', 'usual', 'year', '...', '.hmmmm']\n",
      "[13, 2, 1, 0, 12] ['no_of_words', 'no_of_verbs', 'pos_query_word', 'word_before', 'word_after']\n",
      "[[13 2 1 0 12]] (1, 5)\n",
      "PRIORITY:  [0]\n",
      "\n",
      " Class: 1\n",
      "\n",
      "Tweet: RT @HSELive: We can all play our part in slowing the spread of #coronavirus. Watch this video to find out all you can do. #ItsInOurHands #C…\n",
      "\n",
      "['rt', 'play', 'part', 'slowing', 'spread', 'coronavirus', 'watch', 'video', 'find', 'itsinourhands', 'c…']\n",
      "\n",
      " Class: 0\n",
      "\n",
      "Tweet: RT @guardian: Coronavirus live updates: death toll in Spain reaches 1,000 as Germany threatens further curfews https://t.co/92IuwJWSQR\n",
      "\n",
      "['rt', 'coronavirus', 'live', 'updates', 'death', 'toll', 'spain', 'reaches', '1,000', 'germany', 'threatens', 'curfews']\n",
      "[22, 3, 1, 0, 21] ['no_of_words', 'no_of_verbs', 'pos_query_word', 'word_before', 'word_after']\n",
      "[[22 3 1 0 21]] (1, 5)\n",
      "PRIORITY:  [0]\n",
      "\n",
      " Class: 1\n",
      "\n",
      "Tweet: RT @Amy_Siskind: We are up to 14,316 confirmed cases of coronavirus - that’s a 51% increase from yesterday.  Yesterday’s increase was by 44…\n",
      "\n",
      "['rt', '14,316', 'confirmed', 'cases', 'coronavirus', '’', '51', 'increase', 'yesterday', 'yesterday', '’', 'increase', '44…']\n",
      "[31, 4, 13, 12, 18] ['no_of_words', 'no_of_verbs', 'pos_query_word', 'word_before', 'word_after']\n",
      "[[31 4 13 12 18]] (1, 5)\n",
      "PRIORITY:  [0]\n",
      "\n",
      " Class: 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet: RT @A7_MVT: Damn I gotta warn my mum\n",
      "\n",
      "['rt', 'damn', 'got', 'ta', 'warn', 'mum']\n",
      "\n",
      " Class: 0\n",
      "\n",
      "Tweet: RT @TIinExile: The last time a Pope asked God to stop a major epidemic was in 1348.\n",
      "\n",
      "Pope Clement VI  had asked God to stop Black Death pla…\n",
      "\n",
      "['rt', 'last', 'time', 'pope', 'asked', 'god', 'stop', 'major', 'epidemic', '1348.', 'pope', 'clement', 'vi', 'asked', 'god', 'stop', 'black', 'death', 'pla…']\n",
      "\n",
      " Class: 0\n",
      "\n",
      "Tweet: RT @spectatorindex: Most coronavirus deaths\n",
      "\n",
      "Italy: 3405\n",
      "China: 3245\n",
      "Iran: 1284\n",
      "Spain: 830\n",
      "France: 372\n",
      "US: 171\n",
      "UK: 144\n",
      "South Korea: 91\n",
      "Neth…\n",
      "\n",
      "['rt', 'coronavirus', 'deaths', 'italy', '3405', 'china', '3245', 'iran', '1284', 'spain', '830', 'france', '372', 'us', '171', 'uk', '144', 'south', 'korea', '91', 'neth…']\n",
      "[33, 1, 6, 5, 27] ['no_of_words', 'no_of_verbs', 'pos_query_word', 'word_before', 'word_after']\n",
      "[[33 1 6 5 27]] (1, 5)\n",
      "PRIORITY:  [0]\n",
      "\n",
      " Class: 1\n",
      "\n",
      "Tweet: RT @atonedment: the world: there are thousands of people sick with coronavirus around the world. people are really struggling. \n",
      "celebrities…\n",
      "\n",
      "['rt', 'world', 'thousands', 'people', 'sick', 'coronavirus', 'around', 'world', 'people', 'really', 'struggling', 'celebrities…']\n",
      "[25, 3, 15, 14, 10] ['no_of_words', 'no_of_verbs', 'pos_query_word', 'word_before', 'word_after']\n",
      "[[25 3 15 14 10]] (1, 5)\n",
      "PRIORITY:  [1]\n",
      "\n",
      " Class: 1\n",
      "\n",
      "Tweet: RT @_sweet_bread: Day 5 of Coronavirus lock down, stacking Pringles \n",
      "https://t.co/LOj2Y4SwNk\n",
      "\n",
      "['rt', 'day', '5', 'coronavirus', 'lock', 'stacking', 'pringles']\n",
      "\n",
      " Class: 0\n",
      "\n",
      "Tweet: RT @DeShobhaa: We need this in India. Not ghanti bajaoing at 5 p.m. on Sunday. https://t.co/pIU0trN8VT\n",
      "\n",
      "['rt', 'need', 'india', 'ghanti', 'bajaoing', '5', 'p.m.', 'sunday']\n",
      "[22, 1, 1, 0, 21] ['no_of_words', 'no_of_verbs', 'pos_query_word', 'word_before', 'word_after']\n",
      "[[22 1 1 0 21]] (1, 5)\n",
      "PRIORITY:  [0]\n",
      "\n",
      " Class: 1\n",
      "\n",
      "Tweet: RT @IndiaToday: #IndiaFightsCorona | UP health minister, who met #KanikaKapoor at #Lucknow party, in self-isolation\n",
      "(By @neelanshu512)\n",
      "http…\n",
      "\n",
      "['rt', 'indiafightscorona', 'health', 'minister', 'met', 'kanikakapoor', 'lucknow', 'party', 'self-isolation', 'http…']\n",
      "\n",
      " Class: 0\n",
      "\n",
      "Tweet: @ABCPolitics @ABC NPR/Marist Poll \n",
      "44% approve, 49% do not approve handling coronavirus .\n",
      "https://t.co/OQy11tWD8d\n",
      "\n",
      "['npr/marist', 'poll', '44', 'approve', '49', 'approve', 'handling', 'coronavirus']\n",
      "[21, 3, 17, 16, 4] ['no_of_words', 'no_of_verbs', 'pos_query_word', 'word_before', 'word_after']\n",
      "[[21 3 17 16 4]] (1, 5)\n",
      "PRIORITY:  [0]\n",
      "\n",
      " Class: 1\n",
      "\n",
      "Tweet: RT @EricLiptonNYT: At least FOUR US Senators or their spouses sold large amounts of stock before the market tanked. Story updated with othe…\n",
      "\n",
      "['rt', 'least', 'four', 'us', 'senators', 'spouses', 'sold', 'large', 'amounts', 'stock', 'market', 'tanked', 'story', 'updated', 'othe…']\n",
      "[26, 3, 1, 0, 25] ['no_of_words', 'no_of_verbs', 'pos_query_word', 'word_before', 'word_after']\n",
      "[[26 3 1 0 25]] (1, 5)\n",
      "PRIORITY:  [0]\n",
      "\n",
      " Class: 1\n",
      "\n",
      "Tweet: These GOP Senators Sold Millions Worth of Stock After Private Briefings on the Impending Coronavirus Crisis -…… https://t.co/fVx0tMgewj\n",
      "\n",
      "['gop', 'senators', 'sold', 'millions', 'worth', 'stock', 'private', 'briefings', 'impending', 'coronavirus', 'crisis', '-……']\n",
      "[20, 1, 1, 0, 19] ['no_of_words', 'no_of_verbs', 'pos_query_word', 'word_before', 'word_after']\n",
      "[[20 1 1 0 19]] (1, 5)\n",
      "PRIORITY:  [0]\n",
      "\n",
      " Class: 1\n",
      "\n",
      "Tweet: RT @Itz_thoyyn: Imagine if God said black people will not get coronavirus and you already bleach your skin 🤷\n",
      "\n",
      "['rt', 'imagine', 'god', 'said', 'black', 'people', 'get', 'coronavirus', 'already', 'bleach', 'skin', '🤷']\n",
      "\n",
      " Class: 0\n",
      "\n",
      "Tweet: Trevor Noah called out partying spring breakers in Florida who are “acting like the coronavirus ain’t s**t.\"… https://t.co/4K2XLFka30\n",
      "\n",
      "['trevor', 'noah', 'called', 'partying', 'spring', 'breakers', 'florida', '“', 'acting', 'like', 'coronavirus', '’', 's**t.', \"''\", '…']\n",
      "\n",
      " Class: 0\n",
      "\n",
      "Tweet: RT @elbagallery: We are Closed Today &amp; temporarily until further notice while the spread #coronavirus is going on. Keep following us on soc…\n",
      "\n",
      "['rt', 'closed', 'today', 'amp', 'temporarily', 'notice', 'spread', 'coronavirus', 'going', 'keep', 'following', 'us', 'soc…']\n",
      "[29, 6, 20, 19, 9] ['no_of_words', 'no_of_verbs', 'pos_query_word', 'word_before', 'word_after']\n",
      "[[29 6 20 19 9]] (1, 5)\n",
      "PRIORITY:  [1]\n",
      "\n",
      " Class: 1\n",
      "\n",
      "Tweet: RT @_SinceNinety3: Can y’all please just follow the government instructions so we can knock this coronavirus out and be done? I feel like a…\n",
      "\n",
      "['rt', '’', 'please', 'follow', 'government', 'instructions', 'knock', 'coronavirus', 'done', 'feel', 'like', 'a…']\n",
      "\n",
      " Class: 0\n",
      "\n",
      "Tweet: RT @w_terrence: EXPOSING CNN!\n",
      "\n",
      "They called the Coronavirus the Chinese Coronavirus back in January \n",
      "\n",
      "But they are calling President Trump a…\n",
      "\n",
      "['rt', 'exposing', 'cnn', 'called', 'coronavirus', 'chinese', 'coronavirus', 'back', 'january', 'calling', 'president', 'trump', 'a…']\n",
      "[24, 3, 1, 0, 23] ['no_of_words', 'no_of_verbs', 'pos_query_word', 'word_before', 'word_after']\n",
      "[[24 3 1 0 23]] (1, 5)\n",
      "PRIORITY:  [1]\n",
      "\n",
      " Class: 1\n",
      "\n",
      "Tweet: RT @K_JeanPierre: Sen. Kelly Loeffler Dumped Millions in Stock After Coronavirus Briefing:\n",
      "\n",
      "She sold off seven figures’ worth of stock hold…\n",
      "\n",
      "['rt', 'sen.', 'kelly', 'loeffler', 'dumped', 'millions', 'stock', 'coronavirus', 'briefing', 'sold', 'seven', 'figures', '’', 'worth', 'stock', 'hold…']\n",
      "[25, 1, 1, 0, 24] ['no_of_words', 'no_of_verbs', 'pos_query_word', 'word_before', 'word_after']\n",
      "[[25 1 1 0 24]] (1, 5)\n",
      "PRIORITY:  [0]\n",
      "\n",
      " Class: 1\n",
      "\n",
      "Tweet: RT @kremlincardinal: Idris Elba did not...\n",
      "\n",
      "- guard the Bifrost\n",
      "- cancel the apocalypse\n",
      "- captain the Prometheus\n",
      "- explore deep space\n",
      "- cam…\n",
      "\n",
      "['rt', 'idris', 'elba', '...', 'guard', 'bifrost', 'cancel', 'apocalypse', 'captain', 'prometheus', 'explore', 'deep', 'space', 'cam…']\n",
      "\n",
      " Class: 0\n",
      "\n",
      "Tweet: RT @GuardianUS: US authorities battle surge in coronavirus scams, from phishing to fake treatments https://t.co/2W8jhpGWvt\n",
      "\n",
      "['rt', 'us', 'authorities', 'battle', 'surge', 'coronavirus', 'scams', 'phishing', 'fake', 'treatments']\n",
      "[20, 3, 10, 9, 10] ['no_of_words', 'no_of_verbs', 'pos_query_word', 'word_before', 'word_after']\n",
      "[[20 3 10 9 10]] (1, 5)\n",
      "PRIORITY:  [0]\n",
      "\n",
      " Class: 1\n",
      "\n",
      "Tweet: RT @SRuhle: Here’s an idea - @SenatorBurr @SenatorLoeffler \n",
      "May I suggest both of you donate the gains from your stock sales to your local…\n",
      "\n",
      "['rt', '’', 'idea', 'may', 'suggest', 'donate', 'gains', 'stock', 'sales', 'local…']\n",
      "[30, 3, 1, 0, 29] ['no_of_words', 'no_of_verbs', 'pos_query_word', 'word_before', 'word_after']\n",
      "[[30 3 1 0 29]] (1, 5)\n",
      "PRIORITY:  [0]\n",
      "\n",
      " Class: 1\n",
      "\n",
      "Tweet: RT @smeredith19: Climate scientists believe the unprecedented measures in place to tackle the coronavirus pandemic give a glimpse of what c…\n",
      "\n",
      "['rt', 'climate', 'scientists', 'believe', 'unprecedented', 'measures', 'place', 'tackle', 'coronavirus', 'pandemic', 'give', 'glimpse', 'c…']\n",
      "[23, 3, 16, 15, 7] ['no_of_words', 'no_of_verbs', 'pos_query_word', 'word_before', 'word_after']\n",
      "[[23 3 16 15 7]] (1, 5)\n",
      "PRIORITY:  [0]\n",
      "\n",
      " Class: 1\n",
      "\n",
      "Tweet: RT @gonzwitter: Really don't wanna fucking hear about how hard it is for celebrities to self-isolate in their multi-million-dollar, multi-a…\n",
      "\n",
      "['rt', 'really', \"n't\", 'wan', 'na', 'fucking', 'hear', 'hard', 'celebrities', 'self-isolate', 'multi-million-dollar', 'multi-a…']\n",
      "\n",
      " Class: 0\n",
      "\n",
      "Tweet: RT @uniofeastanglia: ‘This could change it all’: scientists from @NorwichResearch and @IceniDX are developing a home test kit for #coronavi…\n",
      "\n",
      "['rt', '‘', 'could', 'change', '’', 'scientists', 'developing', 'home', 'test', 'kit', 'coronavi…']\n",
      "[28, 3, 1, 0, 27] ['no_of_words', 'no_of_verbs', 'pos_query_word', 'word_before', 'word_after']\n",
      "[[28 3 1 0 27]] (1, 5)\n",
      "PRIORITY:  [0]\n",
      "\n",
      " Class: 1\n",
      "\n",
      "Tweet: RT @thelindsayellis: The WHO has mandated since 2015 that no diseases be named after places.\n",
      "\n",
      "not that these ghouls give a shit, but just a…\n",
      "\n",
      "['rt', 'mandated', 'since', '2015', 'diseases', 'named', 'places', 'ghouls', 'give', 'shit', 'a…']\n",
      "[29, 6, 1, 0, 28] ['no_of_words', 'no_of_verbs', 'pos_query_word', 'word_before', 'word_after']\n",
      "[[29 6 1 0 28]] (1, 5)\n",
      "PRIORITY:  [0]\n",
      "\n",
      " Class: 1\n",
      "\n",
      "Tweet: RT @business: #Coronavirus latest:\n",
      "-Cases hit 234,309 worldwide; death toll tops 9,800\n",
      "-New York City will run out of medical supplies in 2…\n",
      "\n",
      "['rt', 'coronavirus', 'latest', '-cases', 'hit', '234,309', 'worldwide', 'death', 'toll', 'tops', '9,800', '-new', 'york', 'city', 'run', 'medical', 'supplies', '2…']\n",
      "[28, 3, 1, 0, 27] ['no_of_words', 'no_of_verbs', 'pos_query_word', 'word_before', 'word_after']\n",
      "[[28 3 1 0 27]] (1, 5)\n",
      "PRIORITY:  [0]\n",
      "\n",
      " Class: 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet: RT @thelindsayellis: The WHO has mandated since 2015 that no diseases be named after places.\n",
      "\n",
      "not that these ghouls give a shit, but just a…\n",
      "\n",
      "['rt', 'mandated', 'since', '2015', 'diseases', 'named', 'places', 'ghouls', 'give', 'shit', 'a…']\n",
      "[29, 6, 1, 0, 28] ['no_of_words', 'no_of_verbs', 'pos_query_word', 'word_before', 'word_after']\n",
      "[[29 6 1 0 28]] (1, 5)\n",
      "PRIORITY:  [0]\n",
      "\n",
      " Class: 1\n",
      "\n",
      "Tweet: RT @d_annyc: He can finally be home, sweatpants, hair tied, chilling with no make up on\n",
      "\n",
      "['rt', 'finally', 'home', 'sweatpants', 'hair', 'tied', 'chilling', 'make']\n",
      "\n",
      " Class: 0\n",
      "\n",
      "Tweet: RT @chaotictwitch: let them worship in jail please\n",
      "\n",
      "paul and silas did not have two heads. https://t.co/BUGYaMKl0u\n",
      "\n",
      "['rt', 'let', 'worship', 'jail', 'please', 'paul', 'silas', 'two', 'heads']\n",
      "\n",
      " Class: 0\n",
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'created_at'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-4520dd60590a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mtwitter_streamer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTwitterStreamer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mtwitter_streamer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream_tweets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched_tweets_filename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhash_tag_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-b2d5581a57dc>\u001b[0m in \u001b[0;36mstream_tweets\u001b[1;34m(self, fetched_tweets_filename, hash_tag_list)\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mstream\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mauth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlistener\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtweet_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'extended'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlanguages\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"en\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrack\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'coronavirus'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tweepy\\streaming.py\u001b[0m in \u001b[0;36mfilter\u001b[1;34m(self, follow, track, is_async, locations, stall_warnings, languages, encoding, filter_level)\u001b[0m\n\u001b[0;32m    472\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'filter_level'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilter_level\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    473\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'delimited'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'length'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 474\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_async\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    475\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m     def sitestream(self, follow, stall_warnings=False,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tweepy\\streaming.py\u001b[0m in \u001b[0;36m_start\u001b[1;34m(self, is_async)\u001b[0m\n\u001b[0;32m    387\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_thread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 389\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    390\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_closed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tweepy\\streaming.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    318\u001b[0m             \u001b[1;31m# call a handler first so that the exception can be logged.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 320\u001b[1;33m             \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    321\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    702\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 703\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    704\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    705\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tweepy\\streaming.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    287\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msnooze_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msnooze_time_step\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_connect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 289\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    290\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mssl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSSLError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m                 \u001b[1;31m# This is still necessary, as a SSLError can actually be\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tweepy\\streaming.py\u001b[0m in \u001b[0;36m_read_loop\u001b[1;34m(self, resp)\u001b[0m\n\u001b[0;32m    349\u001b[0m             \u001b[0mnext_status_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_len\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrunning\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mnext_status_obj\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 351\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_status_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    352\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m             \u001b[1;31m# # Note: keep-alive newlines might be inserted before each length value.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tweepy\\streaming.py\u001b[0m in \u001b[0;36m_data\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 323\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    324\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrunning\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-b2d5581a57dc>\u001b[0m in \u001b[0;36mon_data\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mall_data\u001b[0m             \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mcreated_at\u001b[0m           \u001b[1;33m=\u001b[0m \u001b[0mall_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'created_at'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[0mfavorite_count\u001b[0m       \u001b[1;33m=\u001b[0m \u001b[0mall_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'favorite_count'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mfavorited\u001b[0m            \u001b[1;33m=\u001b[0m \u001b[0mall_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'favorited'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'created_at'"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    hash_tag_list = ['coronavirus']\n",
    "    fetched_tweets_filename = \"tweets.json\"\n",
    "    \n",
    "    twitter_streamer = TwitterStreamer()\n",
    "    twitter_streamer.stream_tweets(fetched_tweets_filename, hash_tag_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
