{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Alleged', 'NNP'), ('East', 'NNP'), ('Bay', 'NNP'), ('serial', 'JJ'), ('arsonist', 'NN'), ('arrested', 'VBD'), ('#', '#'), ('SanFrancisco', 'NNP'), ('-', ':'), ('http', 'NN'), (':', ':'), ('//t.co/ojuHfkHVb2', 'NN')]\n",
      "12\n",
      "[('arrested', 'VBD')]\n",
      "1\n",
      "4\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "text = \"Alleged East Bay serial arsonist arrested #SanFrancisco - http://t.co/ojuHfkHVb2\"\n",
    "text = nltk.word_tokenize(text)\n",
    "poslist = nltk.pos_tag(text)\n",
    "print(poslist)\n",
    "\n",
    "verblist = []\n",
    "for i in range(len(poslist)):\n",
    "    if poslist[i][1].startswith('V'):\n",
    "        verblist.append(poslist[i])\n",
    "        \n",
    "        \n",
    "word_count = len(poslist)\n",
    "print(word_count)\n",
    "\n",
    "print(verblist)\n",
    "verb_count = len(verblist)\n",
    "print(verb_count)\n",
    "        \n",
    "query_word = 'arson'\n",
    "\n",
    "words_before = words_after = 0\n",
    "for i in range(len(poslist)):\n",
    "    if poslist[i][0].startswith(query_word):\n",
    "        words_before = i\n",
    "\n",
    "words_after = word_count - words_before \n",
    "\n",
    "print(words_before)\n",
    "print(words_after)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id keyword location  \\\n",
      "0         1     NaN      NaN   \n",
      "1         4     NaN      NaN   \n",
      "2         5     NaN      NaN   \n",
      "3         6     NaN      NaN   \n",
      "4         7     NaN      NaN   \n",
      "5         8     NaN      NaN   \n",
      "6        10     NaN      NaN   \n",
      "7        13     NaN      NaN   \n",
      "8        14     NaN      NaN   \n",
      "9        15     NaN      NaN   \n",
      "10       16     NaN      NaN   \n",
      "11       17     NaN      NaN   \n",
      "12       18     NaN      NaN   \n",
      "13       19     NaN      NaN   \n",
      "14       20     NaN      NaN   \n",
      "15       23     NaN      NaN   \n",
      "16       24     NaN      NaN   \n",
      "17       25     NaN      NaN   \n",
      "18       26     NaN      NaN   \n",
      "19       28     NaN      NaN   \n",
      "20       31     NaN      NaN   \n",
      "21       32     NaN      NaN   \n",
      "22       33     NaN      NaN   \n",
      "23       34     NaN      NaN   \n",
      "24       36     NaN      NaN   \n",
      "25       37     NaN      NaN   \n",
      "26       38     NaN      NaN   \n",
      "27       39     NaN      NaN   \n",
      "28       40     NaN      NaN   \n",
      "29       41     NaN      NaN   \n",
      "...     ...     ...      ...   \n",
      "7583  10835     NaN      NaN   \n",
      "7584  10837     NaN      NaN   \n",
      "7585  10839     NaN      NaN   \n",
      "7586  10840     NaN      NaN   \n",
      "7587  10841     NaN      NaN   \n",
      "7588  10842     NaN      NaN   \n",
      "7589  10843     NaN      NaN   \n",
      "7590  10844     NaN      NaN   \n",
      "7591  10846     NaN      NaN   \n",
      "7592  10847     NaN      NaN   \n",
      "7593  10848     NaN      NaN   \n",
      "7594  10849     NaN      NaN   \n",
      "7595  10850     NaN      NaN   \n",
      "7596  10851     NaN      NaN   \n",
      "7597  10852     NaN      NaN   \n",
      "7598  10853     NaN      NaN   \n",
      "7599  10854     NaN      NaN   \n",
      "7600  10855     NaN      NaN   \n",
      "7601  10859     NaN      NaN   \n",
      "7602  10860     NaN      NaN   \n",
      "7603  10862     NaN      NaN   \n",
      "7604  10863     NaN      NaN   \n",
      "7605  10864     NaN      NaN   \n",
      "7606  10866     NaN      NaN   \n",
      "7607  10867     NaN      NaN   \n",
      "7608  10869     NaN      NaN   \n",
      "7609  10870     NaN      NaN   \n",
      "7610  10871     NaN      NaN   \n",
      "7611  10872     NaN      NaN   \n",
      "7612  10873     NaN      NaN   \n",
      "\n",
      "                                                   text  target  \n",
      "0     Our Deeds are the Reason of this #earthquake M...       1  \n",
      "1                Forest fire near La Ronge Sask. Canada       1  \n",
      "2     All residents asked to 'shelter in place' are ...       1  \n",
      "3     13,000 people receive #wildfires evacuation or...       1  \n",
      "4     Just got sent this photo from Ruby #Alaska as ...       1  \n",
      "5     #RockyFire Update => California Hwy. 20 closed...       1  \n",
      "6     #flood #disaster Heavy rain causes flash flood...       1  \n",
      "7     I'm on top of the hill and I can see a fire in...       1  \n",
      "8     There's an emergency evacuation happening now ...       1  \n",
      "9     I'm afraid that the tornado is coming to our a...       1  \n",
      "10          Three people died from the heat wave so far       1  \n",
      "11    Haha South Tampa is getting flooded hah- WAIT ...       1  \n",
      "12    #raining #flooding #Florida #TampaBay #Tampa 1...       1  \n",
      "13              #Flood in Bago Myanmar #We arrived Bago       1  \n",
      "14    Damage to school bus on 80 in multi car crash ...       1  \n",
      "15                                       What's up man?       0  \n",
      "16                                        I love fruits       0  \n",
      "17                                     Summer is lovely       0  \n",
      "18                                    My car is so fast       0  \n",
      "19                         What a goooooooaaaaaal!!!!!!       0  \n",
      "20                               this is ridiculous....       0  \n",
      "21                                    London is cool ;)       0  \n",
      "22                                          Love skiing       0  \n",
      "23                                What a wonderful day!       0  \n",
      "24                                             LOOOOOOL       0  \n",
      "25                       No way...I can't eat that shit       0  \n",
      "26                                Was in NYC last week!       0  \n",
      "27                                   Love my girlfriend       0  \n",
      "28                                            Cooool :)       0  \n",
      "29                                   Do you like pasta?       0  \n",
      "...                                                 ...     ...  \n",
      "7583  Pic of 16yr old PKK suicide bomber who detonat...       1  \n",
      "7584  These boxes are ready to explode! Exploding Ki...       0  \n",
      "7585  Calgary Police Flood Road Closures in Calgary....       1  \n",
      "7586  #Sismo DETECTADO #JapÌ_n 15:41:07 Seismic inte...       1  \n",
      "7587                                 Sirens everywhere!       0  \n",
      "7588  BREAKING: #ISIS claims responsibility for mosq...       1  \n",
      "7589                                     Omg earthquake       1  \n",
      "7590  SEVERE WEATHER BULLETIN No. 5 FOR: TYPHOON ÛÏ...       1  \n",
      "7591  Heat wave warning aa? Ayyo dei. Just when I pl...       1  \n",
      "7592  An IS group suicide bomber detonated an explos...       1  \n",
      "7593  I just heard a really loud bang and everyone i...       0  \n",
      "7594  A gas thing just exploded and I heard screams ...       1  \n",
      "7595  NWS: Flash Flood Warning Continued for Shelby ...       1  \n",
      "7596  RT @LivingSafely: #NWS issues Severe #Thunders...       1  \n",
      "7597  #??? #?? #??? #??? MH370: Aircraft debris foun...       1  \n",
      "7598  Father-of-three Lost Control of Car After Over...       1  \n",
      "7599  1.3 #Earthquake in 9Km Ssw Of Anza California ...       1  \n",
      "7600  Evacuation order lifted for town of Roosevelt:...       1  \n",
      "7601  #breaking #LA Refugio oil spill may have been ...       1  \n",
      "7602  a siren just went off and it wasn't the Forney...       1  \n",
      "7603  Officials say a quarantine is in place at an A...       1  \n",
      "7604  #WorldNews Fallen powerlines on G:link tram: U...       1  \n",
      "7605  on the flip side I'm at Walmart and there is a...       1  \n",
      "7606  Suicide bomber kills 15 in Saudi security site...       1  \n",
      "7607  #stormchase Violent Record Breaking EF-5 El Re...       1  \n",
      "7608  Two giant cranes holding a bridge collapse int...       1  \n",
      "7609  @aria_ahrary @TheTawniest The out of control w...       1  \n",
      "7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1  \n",
      "7611  Police investigating after an e-bike collided ...       1  \n",
      "7612  The Latest: More Homes Razed by Northern Calif...       1  \n",
      "\n",
      "[7613 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv (r'C:\\Users\\sayali\\Documents\\sarthak\\Twitter Project\\train.csv')\n",
    "print (df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-100-c870fd29cace>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-100-c870fd29cace>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    ipython locate\u001b[0m\n\u001b[1;37m                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "ipython locate RFattrsel.ipnyb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy.core._multiarray_umath'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy.core._multiarray_umath'"
     ]
    },
    {
     "ename": "SystemError",
     "evalue": "<class '_frozen_importlib._ModuleLockManager'> returned a result with an error set",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;31mImportError\u001b[0m: numpy.core.multiarray failed to import",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;31mSystemError\u001b[0m: <class '_frozen_importlib._ModuleLockManager'> returned a result with an error set"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core._multiarray_umath failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;31mImportError\u001b[0m: numpy.core._multiarray_umath failed to import"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.umath failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;31mImportError\u001b[0m: numpy.core.umath failed to import"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import tokenization\n",
    "from plotnine import *\n",
    "from tensorflow.keras.layers import Dense, Input, Concatenate, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
